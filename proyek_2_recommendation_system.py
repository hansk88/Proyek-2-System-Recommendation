# -*- coding: utf-8 -*-
"""Proyek 2 Recommendation System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-qLMvqwTmYDJMX1qxvowvcXI11_Mzi8n
"""

# Import library
import os
import shutil
import zipfile
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Upload file kaggle.json
from google.colab import files
files.upload()

# Membuat folder ~/.kaggle
kaggle_dir = os.path.expanduser("~/.kaggle")
os.makedirs(kaggle_dir, exist_ok=True)

# Memindahkan file yang diupload
shutil.move("kaggle.json", os.path.join(kaggle_dir, "kaggle.json"))

# Mengubah permission
os.chmod(os.path.join(kaggle_dir, "kaggle.json"), 0o600)

# Download dataset dari kaggle
!kaggle datasets download -d parasharmanas/movie-recommendation-system

# Unzip file yang telah didownload
!unzip -o movie-recommendation-system.zip

# Memuat dataset ke dalam bentuk DataFrame
movies = pd.read_csv('movies.csv')
ratings = pd.read_csv('ratings.csv')

# Menampilkan lima baris teratas pada DataFrame movies
movies.head()

# Menampilkan lima baris teratas pada DataFrame ratings
ratings.head()

# Melihat gambaran awal tentang dataset
print('Jumlah data film yang tersedia dalam dataset adalah', len(movies.movieId.unique()))
print('Jumlah data kombinasi genres yang tersedia dalam dataset adalah', len(movies.genres.unique()))
print('Jumlah data user yang memberikan rating dalam dataset adalah', len(ratings.userId.unique()))
print('Jumlah data film yang telah diberikan rating dalam dataset adalah', len(ratings.movieId.unique()))
print('Jumlah pilihan rating yang dapat diberikan adalah', len(ratings.rating.unique()))

# Menampilkan informasi dasar pada DataFrame movies
movies.info()

"""DataFrame movies memiliki total 62,423 baris dengan 3 kolom yang terdiri atas:
- movieId -> bertipe integer
- title -> bertipe object
- genres -> bertipe object
"""

# Melihat jumlah nilai null pada masing-masing kolom untuk DataFrame movies
movies.isnull().sum()

"""Terlihat bahwa setiap entri pada ketiga kolom DataFrame movies tidak ada yang bernilai null"""

# Mengecek apakah ada data duplikat pada DataFrame movies
movies_duplicate_count = movies.duplicated().sum()
print('Jumlah data duplikat pada DataFrame movies:', movies_duplicate_count)

"""Terlihat bahwa DataFrame movies tidak mengandung data duplikat"""

# Menampilkan informasi dasar pada DataFrame ratings
ratings.info()

"""DataFrame ratings memiliki total 25,000,095 baris dengan 4 kolom yang terdiri atas:
- userId -> bertipe integer
- movieId -> bertipe integer
- rating -> bertipe float
- timestamp -> bertipe integer
"""

# Melihat jumlah nilai null pada masing-masing kolom untuk DataFrame ratings
ratings.isna().sum()

"""Terlihat bahwa setiap entri pada keempat kolom DataFrame ratings tidak ada yang bernilai null"""

# Mengecek apakah ada data duplikat pada DataFrame ratings
ratings_duplicate_count = ratings.duplicated().sum()
print('Jumlah data duplikat pada DataFrame ratings:', ratings_duplicate_count)

"""Terlihat bahwa DataFrame ratings tidak mengandung data duplikat"""

# Menampilkan pilihan rating
ratings_list = sorted(float(r) for r in ratings.rating.unique()) # menyortir dari terkecil ke terbesar
print('Pilihan rating yang dapat diberikan:', ratings_list)

# Menghitung berapa kali sebuah rating dipilih
rating_counts = ratings['rating'].value_counts().sort_index()

# Menampilkan hasil dalam diagram batang
plt.figure(figsize=(5, 3))
plt.bar(rating_counts.index, rating_counts.values, width=0.4)
plt.xlabel('Rating')
plt.ylabel('Jumlah user')
plt.title('Perbandingan Rating dari User')
plt.xticks(rating_counts.index)
plt.grid(axis='y', linestyle='--')
plt.tight_layout()
plt.show()

"""Terlihat bahwa lebih dari 6,000,000 user memberikan rating 4.0 sehingga rating ini adalah yang paling banyak diberi. Sementara itu, terdapat kurang dari 500,000 user yang memberikan rating 0.5 sehingga rating ini adalah jumlah yang paling sedikit diberi"""

# Melihat distribusi rating
ratings['rating'].describe()

"""Didapati rata-rata rating yang diberikan yaitu 3.53 dengan standar deviasi 1.06. Rating yang diberikan memiliki nilai terkecil yaitu 0.5 dan nilai terbesar yaitu 5.0"""

# Menggabungkan DataFrame movies dan ratings
movie_rating = pd.merge(movies, ratings, on='movieId', how='right')

# Menampilkan DataFrame gabungan
movie_rating.head()

# Mengecek jumlah nilai null pada DataFrame gabungan
movie_rating.isna().sum()

# Mengecek apakah ada data duplikat pada DataFrame gabungan
duplicate_count = movie_rating.duplicated().sum()
print('Jumlah data duplikat pada DataFrame gabungan:', duplicate_count)

# Mengurutkan DataFrame berdasarkan movieId
movie_rating.sort_values('movieId', ascending=True)

# Mengecek apakah setiap title memiliki tepat satu movieId dan genres yang sama
check = movie_rating.groupby('title')[['movieId', 'genres']].nunique()
non_unique = check[(check['movieId'] > 1) | (check['genres'] > 1)]
non_unique

"""Terlihat ada 89 sampel dimana sebuah title memiliki lebih dari satu movieId dan genres yang berbeda"""

# Memilih nilai modus untuk movieId dan genres dari sebuah title yang sama
fix = (
    movie_rating.groupby('title').agg({
        'movieId': lambda x: x.mode().iloc[0],
        'genres': lambda x: x.mode().iloc[0]
    })
)

# Menyamakan movieId dan genres untuk satu title yang sama
movie_rating['movieId'] = movie_rating['title'].map(fix['movieId'])
movie_rating['genres'] = movie_rating['title'].map(fix['genres'])

# Memastikan sebuah title hanya memiliki satu movieId dan satu genres
check = movie_rating.groupby('title')[['movieId', 'genres']].nunique()
non_unique = check[(check['movieId'] > 1) | (check['genres'] > 1)]
if non_unique.empty:
    print("Semua title memiliki tepat satu movieId dan satu genres")
else:
    print("Ada title yang memiliki lebih dari satu movieId atau lebih dari satu genres")

# Inisialisasi movie_rating sebagai df
df = movie_rating

# Mengubah userId menjadi list tanpa nilai yang sama
user_ids = df['userId'].unique().tolist()

# Melakukan encoding userId
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}

# Melakukan proses encoding angka ke ke userId
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}

# Mengubah movieId menjadi list tanpa nilai yang sama
movie_ids = df['movieId'].unique().tolist()

# Melakukan proses encoding movieId
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}

# Melakukan proses encoding angka ke movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

# Mapping userId ke dataframe user
df['user'] = df['userId'].map(user_to_user_encoded)

# Mapping movieId ke dataframe movie
df['movie'] = df['movieId'].map(movie_to_movie_encoded)

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)

# Mendapatkan jumlah movie
num_movie = len(movie_encoded_to_movie)

# Mengubah rating menjadi nilai float
df['rating'] = df['rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(df['rating'])

# Nilai maksimal rating
max_rating = max(df['rating'])

print('Jumlah user: {}, Jumlah film: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

# Mengonversi data series movieId ke dalam bentuk list
movie_id = df['movieId'].tolist()

# Mengonversi data series title ke dalam bentuk list
movie_title = df['title'].tolist()

# Mengonversi data series genres ke dalam bentuk list
movie_genres = df['genres'].tolist()

# Membuat dictionary untuk movie_Id, title, dan genres
movies = pd.DataFrame({
    'id': movie_id,
    'title': movie_title,
    'genres': movie_genres
})

# Menampilkan movies
movies

# Mengacak dataset
df = df.sample(frac=1, random_state=42)

# Menampilkan df
df.head()

# Membuat variabel x untuk mencocokkan data user dan movie menjadi satu value
x = df[['user', 'movie']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi dataset dengan proporsi 80% untuk data train dan 20% untuk data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

"""### Collaborative Filtering"""

# Mendefinisikan model
class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.movie_embedding = layers.Embedding( # layer embeddings movie
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1) # layer embedding movie bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    movie_vector = self.movie_embedding(inputs[:, 1]) # memanggil layer embedding 3
    movie_bias = self.movie_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)

    x = dot_user_movie + user_bias + movie_bias

    return tf.nn.sigmoid(x) # aktivasi fungsi sigmoid

# Inisialisasi model
model = RecommenderNet(num_users, num_movie, 50)

# Model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Membuat fungsi callback
early_stop = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=5,
)

# Memulai training model
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 2048,
    epochs = 20,
    validation_data = (x_val, y_val),
    callbacks=[early_stop]
)

# Menampilkan RMSE selama pelatihan
plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Proses training berjalan selama 5 epoch sebelum dihentikan. Dari proses pelatihan, diperoleh nilai error akhir sekitar 0.48 dan error pada data validasi sekitar 0.42."""

# Mengambil sample user
user_id = df.userId.sample(1).iloc[0]
movie_watched_by_user = df[df.userId == user_id]

# Operator bitwise (~)
movie_not_watched = movies[~movies['id'].isin(movie_watched_by_user.movieId.values)]['id']
movie_not_watched = list(
    set(movie_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movie_not_watched = [[movie_to_movie_encoded.get(x)] for x in movie_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)

# Memprediksi rating
ratings = model.predict(user_movie_array).flatten()

# Mengurutkan rating untuk 10 film terbaik
sorted_indices = ratings.argsort()[::-1]
seen = set()
recommended_movie_ids = []

for idx in sorted_indices:
    movie_id = movie_encoded_to_movie.get(movie_not_watched[idx][0])
    if movie_id and movie_id not in seen:
        recommended_movie_ids.append(movie_id)
        seen.add(movie_id)
    if len(recommended_movie_ids) == 10:
        break

# Menampilkan hasil pengerjaan
print('Menunjukkan rekomendasi film untuk user: {}'.format(user_id))
print('=============================================\n')
print('Film dengan rating tertinggi dari user')
print('---------------------------------------------')

top_movie_user = (
    movie_watched_by_user.sort_values(
        by='rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movies_df_rows = movies.drop_duplicates(subset='id')  # menghapus data duplikat (jika ada)

for row in movies_df_rows[movies_df_rows['id'].isin(top_movie_user)].itertuples():
    print(row.title, ':', row.genres)

print('\n---------------------------------------------')
print('Top 10 rekomendasi film')
print('---------------------------------------------')

# Memastikan setiap film hanya muncul satu kali dalam rekomendasi
recommended_movie = movies.drop_duplicates(subset='id')
recommended_movie = recommended_movie[recommended_movie['id'].isin(recommended_movie_ids)]

# Mencetak rekomendasi film
for row in recommended_movie.itertuples():
    print(row.title, ':', row.genres)